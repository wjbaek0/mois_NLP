{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "import jpype\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_identifier(word):\n",
    "    jpype.attachThreadToJVM()\n",
    "    morps = kkma.pos(word)\n",
    "    v = False\n",
    "    result = []\n",
    "    for m,p in morps:\n",
    "        if p == 'XSV' or p == 'VV':\n",
    "            v = True\n",
    "\n",
    "    if v:\n",
    "        for i in range(len(morps)):\n",
    "            m,p = morps[i]\n",
    "            if p == 'VA' or p == 'VV':\n",
    "                if m[0] == word[0] and len(m) >= 1:\n",
    "                    result.append(m)\n",
    "                    break\n",
    "            if i > 0 and p == 'XSV':\n",
    "                r = morps[i-1][0]+m\n",
    "                if r[0] == word[0]:\n",
    "                    result.append(r)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tokenizer(text):\n",
    "    tokens = text.split(' ')\n",
    "    idxs = []\n",
    "    for i in range(len(tokens)):\n",
    "        idxs.append(str(i))\n",
    "    return idxs, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2tgt_data(input_data):\n",
    "    result = []\n",
    "    for item in input_data:\n",
    "        ori_tokens, ori_preds = item[0],item[1]\n",
    "        for idx in range(len(ori_preds)):\n",
    "            pred = ori_preds[idx]\n",
    "            if pred != '_':\n",
    "                if idx == 0:\n",
    "                    begin = idx\n",
    "                elif ori_preds[idx-1] == '_':\n",
    "                    begin = idx\n",
    "                end = idx\n",
    "        tokens, preds = [],[]\n",
    "        for idx in range(len(ori_preds)):\n",
    "            token = ori_tokens[idx]\n",
    "            pred = ori_preds[idx]\n",
    "            if idx == begin:\n",
    "                tokens.append('<tgt>')\n",
    "                preds.append('_')\n",
    "\n",
    "            tokens.append(token)\n",
    "            preds.append(pred)\n",
    "\n",
    "            if idx == end:\n",
    "                tokens.append('</tgt>')\n",
    "                preds.append('_')\n",
    "        sent = []\n",
    "        sent.append(tokens)\n",
    "        sent.append(preds)\n",
    "        result.append(sent)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    result = []\n",
    "    idxs, tokens = basic_tokenizer(text)\n",
    "    for idx in range(len(tokens)):\n",
    "        token = tokens[idx]\n",
    "        verb_check = pred_identifier(token)\n",
    "        \n",
    "        if verb_check:\n",
    "            preds = ['_' for i in range(len(tokens))]\n",
    "            preds[idx] = verb_check[0]+'.v'\n",
    "            instance = []            \n",
    "#             instance.append(idxs)\n",
    "            instance.append(tokens)\n",
    "            instance.append(preds)\n",
    "\n",
    "            result.append(instance)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['애플은', '미국에서', '태어난', '스티브', '잡스가', '설립한', '컴퓨터', '회사이다.'], ['_', '_', '태어나.v', '_', '_', '_', '_', '_']], [['애플은', '미국에서', '태어난', '스티브', '잡스가', '설립한', '컴퓨터', '회사이다.'], ['_', '_', '_', '_', '_', '설립하.v', '_', '_']]]\n",
      "[[['애플은', '미국에서', '<tgt>', '태어난', '</tgt>', '스티브', '잡스가', '설립한', '컴퓨터', '회사이다.'], ['_', '_', '_', '태어나.v', '_', '_', '_', '_', '_', '_']], [['애플은', '미국에서', '태어난', '스티브', '잡스가', '<tgt>', '설립한', '</tgt>', '컴퓨터', '회사이다.'], ['_', '_', '_', '_', '_', '_', '설립하.v', '_', '_', '_']]]\n"
     ]
    }
   ],
   "source": [
    "# text = '애플은 스티브 잡스와 스티브 워즈니악과 론 웨인이 1976년에 설립한 컴퓨터 회사이다.'\n",
    "# text= '애플은 미국에서 태어난 스티브 잡스가 설립한 컴퓨터 회사이다.'\n",
    "\n",
    "# d = preprocessing(text)\n",
    "# print(d)\n",
    "\n",
    "# z = data2tgt_data(d)\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('설립', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD')]\n",
      "설립하.v\n"
     ]
    }
   ],
   "source": [
    "# text = '설립한'\n",
    "# d = pred_identifier(text)\n",
    "# print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
